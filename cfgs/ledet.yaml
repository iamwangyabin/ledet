arch: "poundnet"
resume: null
name: "ledet_poundnet_ViTL_Progan"

train:
  pipeline: engine.ledet_trainer
  seed: 38534
  train_epochs: 1
  gradient_accumulation_steps: 1
  check_val_every_n_epoch: 1

  lambda_reg: 1e-2
  ema_momentum: 0.99
  num_slices: 64
  ep_num_points: 17
  t_max: 5.0
  sigma: 1.0
  min_count: 8
  eps: 1e-6

  optimizer:
    _target_: torch.optim.AdamW
    _partial_: True
    lr: 1e-4
    weight_decay: 1e-3
    betas: [ 0.9, 0.999 ]

  scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingLR
    _partial_: True
    T_max: ${train.train_epochs}

model:
  NAME: "ViT-L/14"
  N_CTX_VISION: 16
  N_CTX_TEXT: 16
  CTX_INIT: False
  PROMPT_DEPTH_VISION: 8
  PROMPT_DEPTH_TEXT: 8
  PROMPT_NUM_TEXT: 1

datasets:
  base_path: "/home/data/yabin/DF-arrow"
  train:
    source:
      - { target: data.ArrowDatasets,
          data_root: '${datasets.base_path}/ForenSynths',
          sub_sets: ["airplane", "bird", "bottle", "car", "chair", "diningtable", "horse", "person", "sheep", "train",
                       "bicycle", "boat", "bus", "cat", "cow", "dog", "motorbike", "pottedplant", "sofa", "tvmonitor"],
          split: 'train_binary' }
    multicalss_names: ["airplane", "bird", "bottle", "car", "chair", "diningtable", "horse", "person", "sheep", "train",
                       "bicycle", "boat", "bus", "cat", "cow", "dog", "motorbike", "pottedplant", "sofa", "tvmonitor"]
    batch_size: 32
    loader_workers: 16
    trsf:
      - _target_: torchvision.transforms.Resize
        size: 256
      - _target_: torchvision.transforms.RandomResizedCrop
        size: 224
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: data.DataAugment
        blur_prob: 0.1
        blur_sig: [ 0.0, 3.0 ]
        jpg_prob: 0.1
        jpg_method: [ 'cv2', 'pil' ]
        jpg_qual: [ 60, 100 ]
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [ 0.48145466, 0.4578275, 0.40821073 ]
        std: [ 0.26862954, 0.26130258, 0.27577711 ]

  val:
    source:

      - { target: data.ArrowDatasets,
          data_root: '${datasets.base_path}/DIF',
          sub_sets: [ 'dalle_2',  'dalle_mini',  'glide',  'mj',  'sd14',  'sd21', ],
          split: 'test',
          benchmark_name: 'DIF'}

    batch_size: 128
    loader_workers: 32
    trsf:
      - _target_: data.RandomCompress
        method: "JPEG"
        qf: [70, 100]
      - _target_: torchvision.transforms.Resize
        size: 256
      - _target_: torchvision.transforms.CenterCrop
        size: 224
      - _target_: torchvision.transforms.ToTensor
      - _target_: torchvision.transforms.Normalize
        mean: [0.48145466, 0.4578275, 0.40821073]
        std: [0.26862954, 0.26130258, 0.27577711]
